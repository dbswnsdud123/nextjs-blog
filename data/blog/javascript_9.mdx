---
title: '웹 성능 최적화 기법 - Core Web Vitals 개선을 위한 실전 가이드'
date: '2025-01-04'
lastmod: '2025-01-04'
tags: ['javascript']
draft: false
summary: '실무에서 바로 적용할 수 있는 웹 성능 최적화 기법을 다룹니다. Core Web Vitals 개선부터 번들 최적화, 이미지 최적화, 렌더링 성능 향상까지 실전 노하우를 소개합니다.'
images: ['/static/images/web-performance-optimization.png']
---

"3초 안에 로딩되지 않으면 사용자는 떠난다." 이 말이 과장이라고 생각하는가? 아마존의 연구에 따르면 페이지 로딩 시간이 100ms 늘어날 때마다 매출이 1% 감소한다고 한다.

하지만 현실은 어떤가? 멋진 애니메이션과 화려한 UI를 만들기 위해 라이브러리를 덕지덕지 붙이고, 이미지는 압축 없이 그대로 사용하고, 번들 크기는 신경 쓰지 않는다. 그러다가 사용자가 "사이트가 느리다"고 불평하면 그제야 당황한다.

이 글에서는 **실무에서 바로 써먹을 수 있는** 웹 성능 최적화 기법들을 알아보자. 이론적인 이야기가 아니라, 진짜 측정 가능한 결과를 만들어내는 방법들이다.

<TOCInline toc={props.toc} exclude="" />

## Core Web Vitals 이해하기

구글이 정한 웹 성능 지표다. SEO에도 직접적으로 영향을 미치므로 무시할 수 없다. 이 지표들이 중요한 이유는 단순히 구글이 정했기 때문이 아니라, 실제 사용자 경험과 직결되기 때문이다.

### 1. LCP (Largest Contentful Paint)

페이지에서 가장 큰 콘텐츠 요소가 화면에 렌더링되는 시간이다. 2.5초 이내가 목표다. 보통 히어로 이미지나 메인 텍스트 블록이 대상이 된다.

LCP를 개선하려면 먼저 어떤 요소가 LCP인지 파악해야 한다. 대부분의 경우 이미지나 텍스트 블록인데, 이미지라면 압축과 최적화가 필요하고, 텍스트라면 폰트 로딩 최적화가 중요하다.

```javascript
// LCP 측정의 핵심 부분
new PerformanceObserver((entryList) => {
  const entries = entryList.getEntries()
  const lastEntry = entries[entries.length - 1] // 가장 마지막 LCP 엔트리가 최종값

  console.log('LCP 요소:', lastEntry.element) // 어떤 요소가 LCP인지 확인
  console.log('LCP 시간:', lastEntry.startTime)
}).observe({ type: 'largest-contentful-paint', buffered: true })
```

### 2. FID (First Input Delay)

사용자가 첫 번째 상호작용을 했을 때 브라우저가 응답하기까지의 시간이다. 100ms 이내가 목표다. 클릭했는데 반응이 없으면 사용자는 짜증을 낸다.

FID가 나쁜 주요 원인은 메인 스레드를 블로킹하는 자바스크립트 코드다. 페이지 로딩 중에 무거운 계산이나 대용량 데이터 처리를 하면 브라우저가 사용자 입력에 반응할 수 없다.

해결책은 작업을 작은 단위로 나누어 처리하는 것이다. `requestIdleCallback`을 사용하면 브라우저가 여유 있을 때만 작업을 처리할 수 있다.

```javascript
// 긴 작업을 청크로 나누는 핵심 아이디어
function processLargeDataset(data) {
  const CHUNK_SIZE = 1000 // 한 번에 처리할 항목 수
  let index = 0

  function processChunk() {
    const endIndex = Math.min(index + CHUNK_SIZE, data.length)

    for (let i = index; i < endIndex; i++) {
      processItem(data[i])
    }

    index = endIndex

    if (index < data.length) {
      requestIdleCallback(processChunk) // 브라우저 여유 시간에 다음 청크 처리
    }
  }

  processChunk()
}
```

### 3. CLS (Cumulative Layout Shift)

예상치 못한 레이아웃 변경으로 인한 사용자 경험 저하를 측정한다. 0.1 이하가 목표다. 읽고 있던 텍스트가 갑자기 밑으로 밀려나거나, 클릭하려던 버튼이 움직이는 경험은 정말 짜증난다.

CLS가 발생하는 주요 원인은 크기가 지정되지 않은 이미지, 동적으로 삽입되는 광고, 웹폰트 로딩 등이다. 이를 방지하려면 모든 미디어 요소에 명시적으로 크기를 지정하고, 동적 콘텐츠를 위한 공간을 미리 확보해야 한다.

## 번들 최적화 전략

번들 크기는 초기 로딩 시간에 직접적인 영향을 미친다. 하지만 무작정 작게 만드는 것보다는 **사용자가 필요한 시점에 필요한 만큼만** 로드하는 것이 중요하다.

### 1. 코드 분할 (Code Splitting)

모든 코드를 한 번에 로드할 필요는 없다. 사용자가 실제로 방문하는 페이지의 코드만 로드하면 초기 로딩 시간을 크게 단축할 수 있다.

라우트 기반 코드 분할이 가장 기본적이고 효과적이다. 홈페이지 방문자가 굳이 관리자 페이지 코드까지 다운로드할 필요는 없지 않은가?

```javascript
// 라우트별로 코드를 분할하는 것이 핵심
const HomePage = lazy(() => import('./pages/HomePage'))
const AdminPage = lazy(() => import('./pages/AdminPage')) // 관리자만 필요한 코드

// 컴포넌트 레벨에서도 분할 가능
const HeavyChart = lazy(() => import('./components/HeavyChart'))

function Dashboard() {
  const [showChart, setShowChart] = useState(false)

  return (
    <div>
      <button onClick={() => setShowChart(true)}>차트 보기</button>
      {showChart && (
        <Suspense fallback={<div>차트 로딩 중...</div>}>
          <HeavyChart />
        </Suspense>
      )}
    </div>
  )
}
```

### 2. 트리 셰이킹 (Tree Shaking)

라이브러리에서 실제로 사용하는 부분만 번들에 포함시키는 기법이다. lodash 전체를 import하면 수백 KB가 추가되지만, 필요한 함수만 import하면 몇 KB만 추가된다.

특히 유틸리티 라이브러리나 UI 컴포넌트 라이브러리에서 효과가 크다. 하지만 라이브러리가 ES modules 형태로 제공되어야 하고, 번들러 설정도 올바르게 되어 있어야 한다.

```javascript
// 전체 라이브러리 import (나쁜 예)
import _ from 'lodash' // 전체 라이브러리 (수백 KB)

// 필요한 함수만 import (좋은 예)
import { debounce, throttle } from 'lodash' // 필요한 함수만 (몇 KB)

// 더 나은 방법: 경량 대안 사용
import { debounce } from './utils/debounce' // 직접 구현한 경량 버전
```

### 3. 동적 임포트 (Dynamic Import)

사용자 액션에 따라 필요한 코드만 로드하는 방식이다. 엑셀 내보내기 기능을 모든 사용자가 사용하는 것은 아니므로, 실제로 사용할 때만 관련 라이브러리를 로드하면 된다.

```javascript
// 사용자가 실제로 기능을 사용할 때만 라이브러리 로드
async function handleExportData() {
  const { saveAs } = await import('file-saver') // 필요할 때만 로드
  const XLSX = await import('xlsx')

  // 엑셀 생성 및 다운로드 로직
}
```

## 이미지 최적화 기법

이미지는 웹사이트 용량의 대부분을 차지한다. 하지만 적절한 최적화를 통해 품질 저하 없이 크기를 크게 줄일 수 있다.

### 1. 반응형 이미지와 지연 로딩

모든 이미지를 처음부터 로드할 필요는 없다. 사용자가 실제로 볼 이미지만 로드하고, 디바이스 크기에 맞는 이미지를 제공하는 것이 효율적이다.

지연 로딩(Lazy Loading)은 이미지가 뷰포트에 들어올 때만 로드하는 기법이다. 특히 긴 페이지에서 효과적이다. 100개의 이미지가 있는 페이지에서 사용자가 처음 3개만 보고 떠난다면, 나머지 97개는 불필요한 로드였던 것이다.

```javascript
// Intersection Observer를 사용한 지연 로딩의 핵심
const observer = new IntersectionObserver(
  ([entry]) => {
    if (entry.isIntersecting) {
      loadImage() // 뷰포트에 들어올 때만 이미지 로드
      observer.disconnect()
    }
  },
  { threshold: 0.1 } // 10%가 보일 때 로드 시작
)
```

### 2. 이미지 압축 및 포맷 최적화

같은 이미지라도 포맷에 따라 크기가 크게 달라진다. WebP는 JPEG보다 25-35% 작으면서도 품질은 비슷하다. 하지만 브라우저 지원을 고려해야 한다.

클라이언트에서 이미지를 압축하는 것도 좋은 방법이다. 사용자가 업로드한 고해상도 이미지를 그대로 서버에 전송하는 대신, 클라이언트에서 적절한 크기로 조정하고 압축해서 전송하면 네트워크 비용을 줄일 수 있다.

```javascript
// 클라이언트 사이드 이미지 압축의 핵심 아이디어
function compressImage(file, maxWidth = 1920, quality = 0.8) {
  return new Promise((resolve) => {
    const canvas = document.createElement('canvas')
    const ctx = canvas.getContext('2d')
    const img = new Image()

    img.onload = () => {
      // 비율 유지하면서 크기 조정
      const ratio = Math.min(maxWidth / img.width, maxWidth / img.height)
      canvas.width = img.width * ratio
      canvas.height = img.height * ratio

      ctx.drawImage(img, 0, 0, canvas.width, canvas.height)
      canvas.toBlob(resolve, 'image/jpeg', quality) // 압축률 조정
    }

    img.src = URL.createObjectURL(file)
  })
}
```

## 렌더링 성능 최적화

브라우저가 화면을 그리는 과정을 이해하면 성능 최적화의 방향을 잡을 수 있다. 불필요한 리렌더링을 줄이고, 효율적인 DOM 조작을 하는 것이 핵심이다.

### 1. 가상화 (Virtualization)

수천 개의 아이템을 가진 리스트를 모두 DOM에 렌더링하면 메모리도 많이 차지하고 스크롤도 버벅인다. 가상화는 실제로 화면에 보이는 아이템만 DOM에 렌더링하는 기법이다.

예를 들어 1만 개의 아이템이 있어도 화면에는 10개만 보인다면, 실제로는 10개 정도만 DOM에 존재시키고 스크롤에 따라 내용을 바꾸는 것이다.

```javascript
// 가상화의 핵심 아이디어
const visibleStart = Math.floor(scrollTop / itemHeight) // 보이는 첫 번째 아이템 인덱스
const visibleEnd = Math.min(
  visibleStart + Math.ceil(containerHeight / itemHeight) + 1,
  items.length
)

const visibleItems = items.slice(visibleStart, visibleEnd) // 실제로 렌더링할 아이템들만
```

### 2. 메모이제이션 최적화

React에서 컴포넌트가 불필요하게 리렌더링되는 것을 방지하는 기법이다. 하지만 무작정 `React.memo`를 사용하는 것보다는 실제로 성능 문제가 있는 부분을 찾아서 적용하는 것이 중요하다.

특히 계산 비용이 많이 드는 작업이나 복잡한 데이터 변환 작업은 `useMemo`로 결과를 캐싱하면 효과적이다.

```javascript
// 비용이 많이 드는 계산을 캐싱하는 것이 핵심
const processedData = useMemo(() => {
  return data
    .filter((item) => filters.every((filter) => filter(item))) // 복잡한 필터링
    .sort((a, b) => a.priority - b.priority) // 정렬
    .slice(0, 100) // 상위 100개만
}, [data, filters]) // 의존성이 변경될 때만 재계산
```

### 3. 애니메이션 최적화

부드러운 애니메이션을 위해서는 60fps를 유지해야 한다. 즉, 16ms마다 화면을 업데이트해야 한다. 이를 위해서는 메인 스레드를 블로킹하지 않고, GPU 가속을 활용하는 것이 중요하다.

CSS의 `transform`과 `opacity` 속성은 컴포지터 레이어에서 처리되므로 메인 스레드를 블로킹하지 않는다. 반면 `left`, `top`, `width`, `height` 같은 속성은 레이아웃을 다시 계산하므로 성능에 악영향을 미친다.

```javascript
// GPU 가속을 활용한 애니메이션 최적화
element.style.willChange = 'transform, opacity' // 브라우저에게 변경 예정임을 알림
element.style.transform = 'translateZ(0)' // 하드웨어 가속 강제 활성화
```

## 실무에서 마주치는 성능 함정들

### 1. 메모리 누수

SPA에서 가장 흔한 문제다. 페이지를 이동해도 이전 페이지의 이벤트 리스너나 타이머가 계속 실행되면서 메모리를 차지한다. 특히 `setInterval`이나 `addEventListener`를 정리하지 않으면 메모리 누수가 발생한다.

해결책은 간단하다. 컴포넌트가 언마운트될 때 반드시 정리 작업을 해야 한다. React의 `useEffect`에서 cleanup 함수를 반환하거나, 클래스 컴포넌트에서 `componentWillUnmount`에서 정리하면 된다.

```javascript
// 메모리 누수를 방지하는 핵심 패턴
useEffect(() => {
  const handleScroll = throttle(() => {
    // 스크롤 처리 로직
  }, 16)

  window.addEventListener('scroll', handleScroll, { passive: true })

  return () => {
    window.removeEventListener('scroll', handleScroll) // 반드시 정리
  }
}, [])
```

### 2. 불필요한 리렌더링

React에서 상태가 변경될 때마다 하위 컴포넌트들이 모두 리렌더링되는 것은 자연스러운 현상이다. 하지만 실제로 변경된 부분이 없다면 불필요한 연산이다.

가장 흔한 실수는 매번 새로운 객체나 배열을 생성하는 것이다. 자바스크립트에서 객체는 참조로 비교되므로, 내용이 같아도 매번 새로운 객체를 만들면 React는 변경된 것으로 인식한다.

```javascript
// 문제: 매번 새로운 객체 생성
;<Child config={{ theme: 'dark', size: 'large' }} />

// 해결: 객체를 외부로 분리하거나 useMemo 사용
const childConfig = useMemo(
  () => ({
    theme: 'dark',
    size: 'large',
  }),
  []
)
```

### 3. 비효율적인 API 호출

N+1 쿼리 문제는 클라이언트에서도 발생한다. 리스트의 각 항목에 대해 개별적으로 API를 호출하면 네트워크 요청이 폭증한다.

해결책은 가능한 한 데이터를 배치로 처리하는 것이다. 100개의 사용자 정보가 필요하다면 100번의 API 호출보다는 한 번의 배치 API 호출이 훨씬 효율적이다.

```javascript
// 비효율적: 각 유저마다 개별 API 호출
userIds.map((id) => fetchUser(id))

// 효율적: 한 번의 배치 API 호출
fetchUsersBatch(userIds)
```

## 성능 모니터링의 중요성

성능 최적화는 한 번 하고 끝나는 것이 아니다. 새로운 기능이 추가되고 코드가 변경되면서 성능이 다시 저하될 수 있다. 따라서 지속적인 모니터링이 필요하다.

실제 사용자 환경에서의 성능 데이터를 수집하는 것이 중요하다. 개발자의 고사양 컴퓨터에서는 빠르게 동작하지만, 사용자의 저사양 모바일 기기에서는 느릴 수 있다.

```javascript
// 실제 사용자 성능 데이터 수집의 핵심
const monitor = new PerformanceMonitor()

// 페이지 언로드 시 성능 데이터 전송
window.addEventListener('beforeunload', () => {
  monitor.sendMetrics() // 실제 사용자 환경의 성능 데이터
})
```

성능 예산을 설정하는 것도 도움이 된다. 번들 크기는 250KB 이하, LCP는 2.5초 이하 같은 기준을 정하고 이를 초과하면 경고를 주는 시스템을 만들면 성능 저하를 사전에 방지할 수 있다.

웹 성능 최적화는 사용자 경험을 직접적으로 개선하는 중요한 작업이다. 하지만 모든 것을 한 번에 최적화하려고 하지 말고, 측정을 통해 실제로 문제가 되는 부분을 찾아서 개선하는 것이 효율적이다.

기억해야 할 핵심:

- 측정 없는 최적화는 의미가 없다
- 사용자가 실제로 체감하는 성능 지표에 집중하자
- 조기 최적화보다는 문제 영역을 파악하고 해결하자
- 성능 최적화는 지속적인 과정이다

다음번에 "사이트가 느려요"라는 말을 들었을 때 당황하지 말고, 이 글에서 소개한 방법들을 체계적으로 적용해보자. 분명히 사용자도, 개발자도 만족할 수 있는 결과를 만들어낼 수 있을 것이다.

## 참고 자료

- [Web.dev - Core Web Vitals](https://web.dev/vitals/)
- [Google PageSpeed Insights](https://pagespeed.web.dev/)
- [Chrome DevTools Performance](https://developer.chrome.com/docs/devtools/performance/)
- [React Performance Optimization](https://react.dev/learn/render-and-commit)

---

_성능 최적화는 기술적인 도전이자 사용자를 위한 배려다._
